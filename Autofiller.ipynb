{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST of all, install SSMS (SQL Server MicroSoft)\n",
    "#Second of all, open the SQLQuery1.sql file in SqlServer\n",
    "#Thrid of all, highlight ONLY the first command (create database Brokerage) then click Execute\n",
    "#Fourth of all, highlight the rest of the file lines then click Execute.\n",
    "#by now you should have the database and schema set and done\n",
    "\n",
    "#now you will need to populate it with data\n",
    "\n",
    "#Fifth of all, install pyodbc (nice library btw)\n",
    "\n",
    "#you will then want to connect your database to the ODBC:\n",
    "#   1) open SQL Server\n",
    "#   2) right click on the very first element in object explorer (which is your device obvs)\n",
    "#   3) choose connect\n",
    "#   4) copy the server name\n",
    "#   5) paste it in the server string below\n",
    "\n",
    "\n",
    "#Sixth of all, just run everything below and enjoy :)\n",
    "\n",
    "#OPTIONAL : you don't need to know how to generate the report file, it is so ez though\n",
    "#   just open SSMS\n",
    "#   Select the database \"Brokerage\"\n",
    "#   Right click and select Reports then Standard Reports\n",
    "#   Select any of the reports than seems interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE THIS AFTER EXECUTION\n",
    "\n",
    "Address_df = pd.read_csv('Street_Address_Listing.csv')\n",
    "while (len(Address_df) < 1000000):\n",
    "    Address_df = Address_df.append(Address_df)\n",
    "\n",
    "Address_df.to_csv('Address.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE THIS AFTER EXECUTION\n",
    "\n",
    "names_df = pd.read_csv('NationalNames.csv')\n",
    "while (len(names_df) < 1000000):\n",
    "    names_df = names_df.append(names_df)\n",
    "\n",
    "names_df.to_csv('Names.csv')\n",
    "\n",
    "Department_df = pd.read_csv('2019_free_title_data.csv')\n",
    "while(len(Department_df)<1000000):\n",
    "    Department_df = Department_df.append(Department_df)\n",
    "Department_df.to_csv('Jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "#to return a random Department Name\n",
    "def GenerateRandName(digits):\n",
    "    Random_dept_name = ''\n",
    "    max_len = random.choice(range(9,40))\n",
    "    while len(Random_dept_name) < max_len:\n",
    "        if(digits):\n",
    "            Random_dept_name = Random_dept_name+(random.choice(alphabet+'123456789'))\n",
    "        else:\n",
    "            Random_dept_name = Random_dept_name+(random.choice(alphabet))\n",
    "    return Random_dept_name\n",
    "\n",
    "def GenerateRandomDate():\n",
    "    randDay = random.choice(range(1,29))\n",
    "    randMonth = random.choice(range(1,12))\n",
    "    randYear = random.choice(range(2000,2023))\n",
    "    return pd.to_datetime(str(randDay) + \"/\"+str(randMonth)+\"/\"+str(randYear), dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Server\n",
      "SQL Server Native Client 11.0\n",
      "SQL Server Native Client RDA 11.0\n",
      "ODBC Driver 17 for SQL Server\n",
      "Microsoft Access Driver (*.mdb, *.accdb)\n",
      "Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)\n",
      "Microsoft Access Text Driver (*.txt, *.csv)\n"
     ]
    }
   ],
   "source": [
    "for driver in pyodbc.drivers():\n",
    "    print(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Employee.csv')\n",
    "#Columns in the CSV : first_name Minit last_name Address gender BDate Salary\n",
    "#attributes in our database: Fname Minit Lname Bdate Address_ Sex Salary\n",
    "#print(df['first_name'])\n",
    "\n",
    "#for i in range(1000):\n",
    "#    df.loc[i,'Minit'] = random.choice(alphabet)\n",
    "#df.to_csv('MOCK_DATA.csv')\n",
    "\n",
    "#print(df.iloc[:,:].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iam not sure whether this cell is outdated or not\n",
    "\n",
    "\n",
    "\n",
    "names_df = pd.read_csv('Names.csv')\n",
    "Address_df = pd.read_csv('Address.csv')\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in tqdm(range(30000), desc=\"making Employee.csv: \"):\n",
    "    df.loc[i, 'first_name'] = names_df.loc[i%1000000, 'Name']\n",
    "    df.loc[i, 'Minit'] = alphabet[i%27]\n",
    "    df.loc[i, 'last_name'] = names_df.loc[(i+1)%1000000, 'Name']\n",
    "    df.loc[i, 'Address'] = Address_df.loc[i%1000000, 'FULL ADDRESS']\n",
    "\n",
    "    df.loc[i, 'BDate'] = pd.to_datetime(str((i%28) + 1) + \"/\"+str((i%12) + 1)+\"/\"+str(2000 + i%40), dayfirst=True)\n",
    "    df.loc[i, 'Sex'] = i%3\n",
    "    df.loc[i, 'Salary'] = i*3000\n",
    "\n",
    "\n",
    "df.to_csv('Employee.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting data into Table Employee: 100%|██████████| 1000/1000 [06:40<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3000000, )]\n"
     ]
    }
   ],
   "source": [
    "#QUERIES TO FILL \"Employee\"\n",
    "\n",
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "insert_to_employee = 'INSERT INTO Employee (Fname, Minit, Lname, Address_, Bdate, Sex, Salary) VALUES (?,?,?, ?, ?, ?, ?)'\n",
    "select_all_from_employee = \"select * from Employee\"\n",
    "\n",
    "for i in tqdm(range(1000), desc=\"inserting data into Table Employee: \"):\n",
    "    #lst = [df['first_name'], df['Minit'], df['last_name'], pd.to_datetime(df['BDate']), df['Address'], df['gender'].astype(int), df['Salary'].astype(int)]\n",
    "\n",
    "    #batch size is 3000\n",
    "    lst = df.iloc[(i)*3000: (i+1)*3000,1:].values.tolist()\n",
    "    cursor.executemany(insert_to_employee, lst)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "get_Employees_count = \"select count (*) from Employee\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "count = cursor.execute(get_Employees_count)\n",
    "print(list(count))\n",
    "#for row in cursor:\n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x1b74d233ab0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing by inserting only one row into employees\n",
    "\n",
    "\n",
    "#lst = [df['first_name'][0], df['Minit'][0], df['last_name'][0], pd.to_datetime(df['BDate'][0]), df['Address'][0], int(df['gender'][0]), int(df['Salary'][0])]\n",
    "\n",
    "\n",
    "lst = [df.loc[0,'first_name'], df.loc[0,'Minit'], df.loc[0,'last_name'], df.loc[0,'BDate'], df.loc[0,'Address'], df.loc[0,'Sex'], df.loc[0,'Salary']]\n",
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"INSERT INTO Employee (Fname, Minit, Lname, Bdate, Address_, Sex, Salary) VALUES(?,?,?, ?, ?, ?, ?)\", lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create table Contracts\n",
    "(\n",
    "Name_Company nvarchar(50),\n",
    "Date_created DATE,\n",
    "ProjectID int,\n",
    "Product nvarchar(50),\n",
    "Price int,\n",
    "Date_of_Contract DATE,\n",
    "Emp_Name nvarchar(50),\n",
    "Emp_SSN int,\n",
    "Contractor_Name nvarchar(50),\n",
    "Cont_SSN int,\n",
    "Delivery_Location nvarchar(50),\n",
    "CONSTRAINT Contracts_KEY_COMPOSITE PRIMARY KEY (Product, Emp_SSN, Cont_SSN)\n",
    ");\n",
    "'''\n",
    "names_df = pd.read_csv('Names.csv')\n",
    "location_pd = pd.read_csv('Address.csv')\n",
    "print('Done reading files')\n",
    "\n",
    "Contract_df = pd.DataFrame()\n",
    "Contract_df[0, 'Name_Company'] = \"Alaraby\"\n",
    "Contract_df['Date_created'] = pd.to_datetime('11/11/2000', dayfirst= True)\n",
    "Contract_df['ProjectID'] = 1\n",
    "Contract_df['Product'] = \"Cement\"\n",
    "Contract_df['Price'] = 2000\n",
    "Contract_df['Date_of_Contract'] = pd.to_datetime('11/11/2000', dayfirst=True)\n",
    "Contract_df['Emp_Name'] = \"AYman\"\n",
    "Contract_df['Emp_SSN'] = 1\n",
    "Contract_df['Contractor_Name'] = \"Mohamed\"\n",
    "Contract_df['Cont_SSN'] = 1\n",
    "Contract_df['Delivery_Location'] = \"Helwan\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "temp_df = Contract_df\n",
    "for i in tqdm(range(1, 1000000),desc=\"making Contracts.csv: \"):\n",
    "    temp_df.loc[i, 'Name_Company'] = GenerateRandName(False)\n",
    "    temp_df.loc[i, 'ProjectID'] = i+1\n",
    "    temp_df.loc[i, 'Product'] = 'Prod_'+(GenerateRandName(True))\n",
    "\n",
    "    temp_df.loc[i, 'Price'] = random.choice(range(1,2000000))\n",
    "    temp_df.loc[i, 'Product'] = random.choice(range(1,200000))\n",
    "    temp_df.loc[i, 'Emp_Name'] = names_df.loc[i, 'Name']\n",
    "    temp_df.loc[i, 'Emp_SSN'] = i+1\n",
    "    temp_df.loc[i, 'Contractor_Name'] = names_df.loc[i-1, 'Name']\n",
    "    temp_df.loc[i, 'Cont_SSN'] = 4000000+i\n",
    "    temp_df.loc[i, 'Delivery_Location'] = location_pd.loc[i, 'FULL ADDRESS']\n",
    "    \n",
    "    temp_df.loc[i, 'Date_created'] = GenerateRandomDate()\n",
    "    temp_df['Date_of_Contract'] = GenerateRandomDate()\n",
    "    if(i % 10000 == 0 ):\n",
    "        Contract_df = pd.concat((Contract_df,temp_df), axis=0)\n",
    "        temp_df = pd.DataFrame()\n",
    "        Contract_df.to_csv('Contracts.csv')\n",
    "\n",
    "#Contract_df.to_csv('Contracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modifying contracts: 100%|██████████| 1000000/1000000 [10:40<00:00, 1562.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  (0, 'Name_Company') Date_created  ProjectID  Product  \\\n",
      "0           0                  NaN   2013-05-21        2.0    63999   \n",
      "1           1                  NaN   2011-10-03        3.0    37891   \n",
      "2           2                  NaN   2010-02-24        4.0    88587   \n",
      "3           3                  NaN   2015-08-24        5.0   121650   \n",
      "4           4                  NaN   2019-02-16        6.0   162283   \n",
      "\n",
      "       Price Date_of_Contract   Emp_Name  Emp_SSN Contractor_Name   Cont_SSN  \\\n",
      "0  1063907.0       2000-10-21       Anna      1.0            Mary  4000001.0   \n",
      "1  1381986.0       2000-10-21       Emma      2.0            Anna  4000002.0   \n",
      "2   339553.0       2000-10-21  Elizabeth      3.0            Emma  4000003.0   \n",
      "3  1849411.0       2000-10-21     Minnie      4.0       Elizabeth  4000004.0   \n",
      "4   755588.0       2000-10-21   Margaret      5.0          Minnie  4000005.0   \n",
      "\n",
      "                      Delivery_Location                           Name_Company  \n",
      "0               9007 HIGHLAND RD, STE 9  ciqDzQscRAzPZFxAuJQRVCirDrVjOpBWrLxnZ  \n",
      "1   5830 S SHERWOOD FOREST BLVD, STE A6                     KFqJgCHGVaErlKgdpZ  \n",
      "2  4520 S SHERWOOD FOREST BLVD, STE 103        ukVppMOmkNpJZkERpIqIREwGBNmPzJB  \n",
      "3                 8334 O'HARA CT, STE D                   wXRnxJuvZEnAOFJKmUaU  \n",
      "4               4250 BLOUNT RD, UNIT 14  ajOumJOykLPVbzPznvsvBRLhBseNWNWcsaixK  \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1000000), desc=\"modifying contracts\"):\n",
    "    Contract_df.loc[i,'Emp_SSN'] = i+1\n",
    "\n",
    "Contract_df = Contract_df.iloc[:,1:]\n",
    "Contract_df.to_csv('Contracts.csv')\n",
    "Contract_df = pd.read_csv('Contracts.csv')\n",
    "print(Contract_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.execute('delete from Contracts')\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  (0, 'Name_Company') Date_created  ProjectID  Product  \\\n",
      "0           0                  NaN   2013-05-21        2.0    63999   \n",
      "1           1                  NaN   2011-10-03        3.0    37891   \n",
      "2           2                  NaN   2010-02-24        4.0    88587   \n",
      "3           3                  NaN   2015-08-24        5.0   121650   \n",
      "4           4                  NaN   2019-02-16        6.0   162283   \n",
      "\n",
      "       Price Date_of_Contract   Emp_Name  Emp_SSN Contractor_Name   Cont_SSN  \\\n",
      "0  1063907.0       2000-10-21       Anna      1.0            Mary  4000001.0   \n",
      "1  1381986.0       2000-10-21       Emma      2.0            Anna  4000002.0   \n",
      "2   339553.0       2000-10-21  Elizabeth      3.0            Emma  4000003.0   \n",
      "3  1849411.0       2000-10-21     Minnie      4.0       Elizabeth  4000004.0   \n",
      "4   755588.0       2000-10-21   Margaret      5.0          Minnie  4000005.0   \n",
      "\n",
      "                      Delivery_Location                           Name_Company  \n",
      "0               9007 HIGHLAND RD, STE 9  ciqDzQscRAzPZFxAuJQRVCirDrVjOpBWrLxnZ  \n",
      "1   5830 S SHERWOOD FOREST BLVD, STE A6                     KFqJgCHGVaErlKgdpZ  \n",
      "2  4520 S SHERWOOD FOREST BLVD, STE 103        ukVppMOmkNpJZkERpIqIREwGBNmPzJB  \n",
      "3                 8334 O'HARA CT, STE D                   wXRnxJuvZEnAOFJKmUaU  \n",
      "4               4250 BLOUNT RD, UNIT 14  ajOumJOykLPVbzPznvsvBRLhBseNWNWcsaixK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting data into table Contracts: 100%|██████████| 900/900 [02:32<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(900000, )]\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "Contract_df = pd.read_csv('Contracts.csv')\n",
    "print(Contract_df.head())\n",
    "\n",
    "insert_to_Contracts= \"INSERT INTO Contracts (Date_created, ProjectID, Product, Price, Date_of_Contract, Emp_Name, Emp_SSN, Contractor_Name, Cont_SSN, Delivery_Location,Name_Company) VALUES(?,?,?, ?,?,?,?,?,?,?,?)\"\n",
    "select_all_from_Contracts = \"select * from Contracts\"\n",
    "get_Contracts_count = \"select count (*) from Contracts\"\n",
    "\n",
    "\n",
    "for i in tqdm(range(0,900), desc=\"inserting data into table Contracts\"):\n",
    "    lst = Contract_df.iloc[i*1000:(i+1)*1000,2:].values.tolist()\n",
    "    cursor.executemany(insert_to_Contracts, lst)\n",
    "\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Contracts_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making Department.csv: 100%|██████████| 9999/9999 [00:10<00:00, 966.27it/s] \n"
     ]
    }
   ],
   "source": [
    "''' Department Attributes\n",
    "Dname nvarchar(50),\n",
    "Dnumber int identity (1,1) Primary Key NOT NULL,\n",
    "Mgr_SSN int foreign key references Employee(SSN),\n",
    "Mgr_Start_Date DATE\n",
    "'''\n",
    "Dept_df = pd.DataFrame()\n",
    "Dept_df['Dname'] = GenerateRandName(True)\n",
    "#Dept_df['Dnumber'] = 0\n",
    "Dept_df['Mgr_SSN'] = random.choice(range(1,30))\n",
    "Dept_df['Mgr_Start_Date'] = pd.to_datetime('11/11/2000', dayfirst=True)\n",
    "\n",
    "temp_df = Dept_df\n",
    "for i in tqdm(range(1,10000), desc=\"making Department.csv: \"):\n",
    "    temp_df.loc[i, 'Dname'] = GenerateRandName(True)\n",
    "#    temp_df.loc[i, 'Dnumber'] = i\n",
    "    temp_df.loc[i, 'Mgr_SSN'] = random.choice(range(1,2000000))\n",
    "    temp_df.loc[i, 'Mgr_Start_Date'] = GenerateRandomDate()\n",
    "    \n",
    "\n",
    "\n",
    "Dept_df = pd.concat((Dept_df, temp_df), axis=0)\n",
    "\n",
    "Dept_df = pd.read_csv('Department.csv')\n",
    "while(len(Dept_df) < 1200000):\n",
    "    Dept_df = pd.concat((Dept_df, Dept_df),axis=0)\n",
    "Dept_df.to_csv('Department.csv')\n",
    "\n",
    "Dept_df['Dname'].replace('', np.nan, inplace=True)\n",
    "Dept_df['Mgr_SSN'].replace('', np.nan, inplace=True)\n",
    "Dept_df['Mgr_Start_Date'].replace('', np.nan, inplace=True)\n",
    "\n",
    "Dept_df.dropna(subset=['Dname'], inplace=True)\n",
    "Dept_df.dropna(subset=['Mgr_SSN'], inplace=True)\n",
    "Dept_df.dropna(subset=['Mgr_Start_Date'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting data into Department: 100%|██████████| 1000/1000 [02:17<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1109999, )]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "Dept_df = pd.read_csv('Department.csv')\n",
    "\n",
    "insert_to_Department= \"INSERT INTO Department (Dname, Mgr_SSN, Mgr_Start_Date) VALUES(?,?, ?)\"\n",
    "select_all_from_Department = \"select * from Department\"\n",
    "get_Department_count = \"select count (*) from Department\"\n",
    "\n",
    "for i in tqdm(range (1000), desc=\"inserting data into Department: \"):\n",
    "    lst = Dept_df.iloc[i*1000:(i+1)*1000,1:].values.tolist()\n",
    "    cursor.executemany(insert_to_Department, lst)\n",
    "    \n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Department_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.execute('delete from Dept_Locations')\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making Dept_Locations.csv: 100%|██████████| 900000/900000 [17:09<00:00, 873.97it/s]  \n"
     ]
    }
   ],
   "source": [
    "''' DEPT LOCATION\n",
    "\n",
    "create table Dept_Locations\n",
    "(\n",
    "Dnumber INT foreign key references Department(Dnumber),\n",
    "Dlocation nvarchar(50) NOT NULL,\n",
    "CONSTRAINT Department_KEY_COMPOSITE PRIMARY KEY (Dnumber, Dlocation)\n",
    ");\n",
    "'''\n",
    "\n",
    "DeptLoc_df = pd.DataFrame()\n",
    "Address_df = pd.read_csv('Address.csv')\n",
    "\n",
    "temp_df = DeptLoc_df\n",
    "for i in tqdm(range(900000), desc=\"Making Dept_Locations.csv: \"):\n",
    "    temp_df.loc[i,'Dnumber'] = i+1\n",
    "    temp_df.loc[i,'Dlocation'] = Address_df.loc[random.choice(range(1,400000)), 'FULL ADDRESS']\n",
    "    if(i%20000 == 0):\n",
    "        DeptLoc_df = pd.concat((DeptLoc_df, temp_df), axis=0)\n",
    "        temp_df = pd.DataFrame()\n",
    "        DeptLoc_df.to_csv('Dept_Locations.csv')\n",
    "\n",
    "\n",
    "\n",
    "DeptLoc_df = pd.concat((DeptLoc_df, temp_df), axis=0)\n",
    "DeptLoc_df.to_csv('Dept_Locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.execute('Delete from Dept_Locations')\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Dnumber                  Dlocation\n",
      "0           1      1.0          10082 E POMONA DR\n",
      "1           2      2.0          16933 TENEIYA AVE\n",
      "2           3      3.0          13630 LANDMARK DR\n",
      "3           4      4.0          11733 SUN BELT CT\n",
      "4           5      5.0  17100-17400 BLACKWATER RD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting into Dept_Locations: 100%|██████████| 950/950 [03:39<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, )]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "DeptLoc_df = pd.read_csv('Dept_Locations.csv')\n",
    "print(DeptLoc_df.head())\n",
    "\n",
    "insert_to_DeptLocation = \"INSERT INTO Dept_Locations (Dlocation) VALUES(?)\"\n",
    "select_all_from_DeptLocations = \"select * from Dept_Locations\"\n",
    "get_Dept_location_count = \"select count (*) from Dept_Locations\"\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(950),desc=\"inserting into Dept_Locations: \"):\n",
    "    lst = DeptLoc_df.iloc[i*1000:(i+1)*1000,2].values.tolist()\n",
    "    for s in lst:\n",
    "        try:\n",
    "            cursor.execute(insert_to_DeptLocation, s)\n",
    "        except:\n",
    "            pass\n",
    "   \n",
    "\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Dept_location_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' Intern TABLE ATTRIBUTES\n",
    "(\n",
    "SSN int identity (3000000,1) primary key Not NULL,\n",
    "Fname nvarchar(50),\n",
    "Minit varchar,\n",
    "Lname nvarchar(50),\n",
    "Bdate DATE,\n",
    "Address_ nvarchar(50),\n",
    "Sex tinyint check(Sex between 0 and 2),\n",
    "Salary int,\n",
    "Major nvarchar(50),\n",
    "PNO INT foreign key references Project(Pnumber),\n",
    "Super_SSN int foreign key references Employee(SSN)\n",
    ");\n",
    "'''\n",
    "\n",
    "names_df = pd.read_csv('Names.csv')\n",
    "Address_df = pd.read_csv('Address.csv')\n",
    "jobs_df = pd.read_csv('Jobs.csv')\n",
    "\n",
    "#new empty dataframe\n",
    "df_intern = pd.Dataframe()\n",
    "#df_intern['SSN']=         auto incremented\n",
    "df_intern['Fname']= ['Ayman', 'Mohamed']\n",
    "df_intern['Minit']= ['M', 'R']\n",
    "df_intern['Lname']= ['Reda', 'Abdo']\n",
    "df_intern['Bdate']= [pd.to_datetime(\"20/12/2004\", dayfirst=True), pd.to_datetime(\"11/11/2000\", dayfirst=True)]\n",
    "df_intern['Address_']= [Address_df.loc[1, 'FULL ADDRESS'], Address_df.loc[3, 'FULL ADDRESS']]\n",
    "df_intern['Sex']= [1,1]\n",
    "df_intern['Salary']= [2000,3000]\n",
    "df_intern['Major']= [\"Computer\", \"Engineering\"]\n",
    "df_intern['PNO']= [3, 5]                                                                #MUST BE PRESENT IN THE PNO\n",
    "df_intern['Super_SSN']= [1, 2]\n",
    "\n",
    "\n",
    "temp_df = df_intern\n",
    "for i in tqdm(range(3001000),desc=\"making Intern.csv: \"):\n",
    "    temp_df.loc[i, 'Fname'] = names_df.loc[i%1000000, 'Name']\n",
    "    temp_df.loc[i, 'Minit'] = random.choice(alphabet)\n",
    "    temp_df.loc[i, 'Lname'] = names_df.loc[i%1000000, 'Name']\n",
    "    temp_df.loc[i, 'Address_'] = Address_df.loc[i%1000000, 'FULL ADDRESS']\n",
    "    \n",
    "    randSex = random.choice(range(0,3))\n",
    "    randSalary = random.choice(range(1, 100000))\n",
    "    \n",
    "    temp_df.loc[i, 'Bdate'] = GenerateRandomDate()\n",
    "    temp_df.loc[i, 'Sex'] = randSex\n",
    "    temp_df.loc[i, 'Salary'] = randSalary\n",
    "    temp_df.loc[i, 'Major'] = jobs_df.loc[i%5000, 'top related titles 19']\n",
    "    temp_df.loc[i, 'PNO'] = i%60000                                                               #Specify we have 60000 project\n",
    "    temp_df.loc[i, 'Super_SSN'] = random.choice(range(1,500000))                                  #the first 500000 employees are intern supervisors\n",
    "    if(i%17000 == 0):\n",
    "        df_intern = pd.concat((df_intern, temp_df), axis=0)\n",
    "        temp_df = pd.DataFrame()\n",
    "        df_intern.to_csv('Intern.csv')\n",
    "\n",
    "df_intern = pd.concat((df_intern, temp_df), axis=0)\n",
    "df_intern.to_csv('Intern.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.execute('delete from Intern')\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      Fname Minit      Lname       Bdate  \\\n",
      "0           0       Anna     C       Anna  2000-01-25   \n",
      "1           1       Emma     P       Emma  2001-02-24   \n",
      "2           2  Elizabeth     g  Elizabeth  2000-04-01   \n",
      "3           3     Minnie     y     Minnie  2000-03-27   \n",
      "4           4   Margaret     U   Margaret  2013-05-21   \n",
      "\n",
      "                               Address_  Sex   Salary                  Major  \\\n",
      "0               9007 HIGHLAND RD, STE 9  1.0  57209.0          sales manager   \n",
      "1   5830 S SHERWOOD FOREST BLVD, STE A6  2.0  83730.0              principal   \n",
      "2  4520 S SHERWOOD FOREST BLVD, STE 103  2.0  82711.0                  owner   \n",
      "3                 8334 O'HARA CT, STE D  2.0  53267.0   chief executive offi   \n",
      "4               4250 BLOUNT RD, UNIT 14  0.0  38652.0           math teacher   \n",
      "\n",
      "   Super_SSN  \n",
      "0   220600.0  \n",
      "1   390500.0  \n",
      "2    79200.0  \n",
      "3     3700.0  \n",
      "4   231100.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting into Intern:  41%|████      | 410/1000 [03:37<05:13,  1.88it/s]\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "The second parameter to executemany must not be empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m),desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minserting into Intern: \u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     lst \u001b[39m=\u001b[39m df_intern\u001b[39m.\u001b[39miloc[i\u001b[39m*\u001b[39m\u001b[39m3000\u001b[39m:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m3000\u001b[39m,\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m---> 20\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecutemany(insert_to_Intern, lst)\n\u001b[0;32m     23\u001b[0m connection\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m     25\u001b[0m count \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39mexecute(get_Employees_count)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: The second parameter to executemany must not be empty."
     ]
    }
   ],
   "source": [
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "df_intern = pd.read_csv('Intern.csv')\n",
    "print(df_intern.head())\n",
    "\n",
    "insert_to_Intern = \"INSERT INTO Intern (Fname, Minit, Lname, Bdate, Address_, Sex, Salary, Major, Super_SSN) VALUES(?,?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "select_all_from_Intern = \"select * from Intern\"\n",
    "get_Intern_count = \"select count (*) from Intern\"\n",
    "get_Employees_count = \"select count (*) from Employee\"\n",
    "\n",
    "for i in tqdm(range(1000),desc=\"inserting into Intern: \"):\n",
    "    lst = df_intern.iloc[i*3000:(i+1)*3000,1:].values.tolist()\n",
    "    cursor.executemany(insert_to_Intern, lst)\n",
    "    \n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Employees_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making Works_On.csv: 100%|██████████| 2900000/2900000 [53:17<00:00, 907.09it/s]  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "create table Works_On\n",
    "(\n",
    "ESSN INT foreign key references Employee(SSN),\n",
    "PNO INT foreign key references Project(Pnumber),\n",
    "Hours INT,\n",
    "CONSTRAINT WorksOn_KEY_COMPOSITE PRIMARY KEY (ESSN, PNO)\n",
    ");\n",
    "\n",
    "'''\n",
    "\n",
    "#new empty dataframe\n",
    "df_workson = pd.DataFrame()\n",
    "\n",
    "df_workson[0,'ESSN']= 1\n",
    "df_workson[0,'PNO']= 1\n",
    "df_workson[0,'Hours']= 19\n",
    "\n",
    "PNO_counter = 1\n",
    "tempdf = df_workson\n",
    "for i in tqdm(range(2900000), desc=\"making Works_On.csv: \"):\n",
    "    tempdf.loc[i, 'ESSN'] = i+2\n",
    "    tempdf.loc[i, 'PNO'] = PNO_counter+1\n",
    "    tempdf.loc[i, 'Hours'] = random.randint(15, 50)\n",
    "    if(i%17000 == 0):\n",
    "        PNO_counter = PNO_counter + 1\n",
    "        df_workson = pd.concat((df_workson, tempdf),axis=0)\n",
    "        tempdf = pd.DataFrame()\n",
    "        df_workson.to_csv('Works_On.csv')\n",
    "\n",
    "df_workson = pd.concat((df_workson, tempdf),axis=0)\n",
    "df_workson.to_csv('Works_On.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  ESSN  PNO  Hours\n",
      "0           1   1.0  1.0   46.0\n",
      "1           2   2.0  2.0   44.0\n",
      "2           3   3.0  2.0   45.0\n",
      "3           4   4.0  2.0   24.0\n",
      "4           5   5.0  2.0   20.0\n"
     ]
    }
   ],
   "source": [
    "connection.commit()\n",
    "cursor.execute('delete from Works_On')\n",
    "connection.commit()\n",
    "\n",
    "df_workson = df_workson.iloc[1:,4:]\n",
    "df_workson.to_csv('Works_On.csv')\n",
    "df_workson = pd.read_csv('Works_On.csv')\n",
    "print(df_workson.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  ESSN  PNO  Hours\n",
      "0           1   1.0  1.0   46.0\n",
      "1           2   2.0  2.0   44.0\n",
      "2           3   3.0  2.0   45.0\n",
      "3           4   4.0  2.0   24.0\n",
      "4           5   5.0  2.0   20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting into Works_On: 100%|██████████| 965/965 [04:34<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, )]\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "df_workson = pd.read_csv('Works_On.csv')\n",
    "print(df_workson.head())\n",
    "insert_to_Works_On = \"INSERT INTO Works_On (ESSN, PNO, Hours) VALUES(?,?,?)\"\n",
    "select_all_from_Works_On = \"select * from Works_On\"\n",
    "get_Works_On_count = \"select count (*) from Works_On\"\n",
    "\n",
    "\n",
    "for i in tqdm(range(965), desc=\"inserting into Works_On: \"):\n",
    "    lst = df_workson.iloc[i*3000:(i+1)*3000,1:].values.tolist()\n",
    "    cursor.executemany(insert_to_Works_On, lst)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Works_On_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "create table Dependent_\n",
    "(\n",
    "ESSN INT foreign key references Employee(SSN),\n",
    "Dependent_Name nvarchar(50) NOT NULL,\n",
    "Sex tinyint check(Sex between 0 and 2),\n",
    "Bdate DATE,\n",
    "Relationship nvarchar(50),\n",
    "CONSTRAINT Dependent_KEY_COMPOSITE PRIMARY KEY (ESSN, Dependent_Name)\n",
    ");\n",
    "'''\n",
    "\n",
    "\n",
    "Relationship_df = pd.read_csv('Relationship.csv')\n",
    "\n",
    "#new empty dataframe\n",
    "df_Dependent = pd.DataFrame()\n",
    "\n",
    "df_Dependent[0,'ESSN']= 1\n",
    "df_Dependent[0,'Dependent_Name']= \"Akram\"\n",
    "df_Dependent[0,'Sex']= 1\n",
    "df_Dependent[0,'Bdate']= pd.to_datetime('11/11/2000', dayfirst=True)\n",
    "df_Dependent[0,'Relationship']= \"Father\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "temp_df = df_Dependent\n",
    "for i in tqdm(range(2900000), desc=\"making Dependent.csv : \"):\n",
    "    temp_df.loc[i, 'ESSN'] = i+1\n",
    "    temp_df.loc[i, 'Dependent_Name'] = GenerateRandName(False)\n",
    "    temp_df.loc[i, 'Sex'] = random.randint(0, 2)\n",
    "    temp_df.loc[i, 'Bdate'] = GenerateRandomDate()\n",
    "    temp_df.loc[i, 'Relationship'] = Relationship_df.loc[random.randint(0,970),'Relationship']\n",
    "    if(i%17000 == 0):\n",
    "        df_Dependent = pd.concat((df_Dependent, temp_df), axis=0)\n",
    "        temp_df = pd.DataFrame()\n",
    "        df_Dependent.to_csv('Dependent.csv')\n",
    "\n",
    "\n",
    "df_Dependent = pd.concat((df_Dependent, temp_df), axis=0)\n",
    "df_Dependent.to_csv('Dependent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.execute(\"delete from Dependent_\")\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  ESSN                      Dependent_Name  Sex  \\\n",
      "0             0           0   1.0        paZKVTQLByxdXhOCpyxXxLUpiqqj  1.0   \n",
      "1             1           1   2.0       FMQDdqvlxinFUqMVSuGIbqbkLorMc  1.0   \n",
      "2             2           2   3.0            CjuVAbakpmWAYMFsHoCqobKc  2.0   \n",
      "3             3           3   4.0  MmGysbOQtdhSRszpXLMzszspphVNUHeuzT  0.0   \n",
      "4             4           4   5.0                VVXLuargiWnLGulRAkVD  2.0   \n",
      "\n",
      "        Bdate Relationship  \n",
      "0  2019-09-06       Lotlux  \n",
      "1  2001-07-06  Mat Lam Tam  \n",
      "2  2005-08-17     Wrapsafe  \n",
      "3  2001-06-24     Treeflex  \n",
      "4  2017-09-12       Vagram  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting into Dependent_ : 100%|██████████| 960/960 [04:02<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2880000, )]\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "df_Dependent= pd.read_csv('Dependent.csv')\n",
    "print(df_Dependent.head())\n",
    "\n",
    "insert_to_Dependent_ = \"INSERT INTO Dependent_ (ESSN, Dependent_Name, Sex, Bdate, Relationship) VALUES(?,?,?,?,?)\"\n",
    "select_all_from_Dependent_ = \"select * from Dependent_\"\n",
    "get_Dependent__count = \"select count (*) from Dependent_\"\n",
    "\n",
    "\n",
    "for i in tqdm(range(960), desc=\"inserting into Dependent_ : \"):\n",
    "    lst = df_Dependent.iloc[i*3000:(i+1)*3000,2:].values.tolist()\n",
    "    cursor.executemany(insert_to_Dependent_, lst)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Dependent__count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           Pname  \\\n",
      "0           0                              advanced databases   \n",
      "1           1                                              9F   \n",
      "2           2                           LEZ3SwJIykqigwhJ1bPw7   \n",
      "3           3             Vyp3AQZxOF4zQNki7hAU5m5B7X4gY1o3cy6   \n",
      "4           4  ffI4FhNEyXiK9ri5QToVRIBkxg5pUCgOV1m7BB868r2nm8   \n",
      "\n",
      "                              Plocation  DNO  \n",
      "0           7353 HIGHLAND RD, STE B 282  1.0  \n",
      "1               9007 HIGHLAND RD, STE 9  2.0  \n",
      "2   5830 S SHERWOOD FOREST BLVD, STE A6  3.0  \n",
      "3  4520 S SHERWOOD FOREST BLVD, STE 103  4.0  \n",
      "4                 8334 O'HARA CT, STE D  5.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting data into Table Employee: 100%|██████████| 980/980 [02:39<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(980000, )]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "project_df = pd.read_csv('Project.csv')\n",
    "print(project_df.head())\n",
    "\n",
    "insert_to_Project = 'INSERT INTO Project (Pname, Plocation, DNO) VALUES (?,?, ?)'\n",
    "select_all_from_Project = \"select * from Project\"\n",
    "\n",
    "for i in tqdm(range(980), desc=\"inserting data into Table Project: \"):\n",
    "    lst = project_df.iloc[(i)*1000: (i+1)*1000,1:].values.tolist()\n",
    "    cursor.executemany(insert_to_Project, lst)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "get_Project_count = \"select count (*) from Project\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "count = cursor.execute(get_Project_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of Employee : [(3010000, )]\n",
      "size of Department : [(1109999, )]\n",
      "size of Project : [(980000, )]\n",
      "size of Intern : [(1228736, )]\n",
      "size of Contracts : [(900000, )]\n",
      "size of Works_On : [(2895000, )]\n",
      "size of Dept_Locations : [(580012, )]\n"
     ]
    }
   ],
   "source": [
    "data = cursor.execute('select count(*) from Employee')\n",
    "print(\"size of Employee : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Department')\n",
    "print(\"size of Department : \" + str(list(data)))\n",
    "\n",
    "\n",
    "data = cursor.execute('select count(*) from Project')\n",
    "print(\"size of Project : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Intern')\n",
    "print(\"size of Intern : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Contracts')\n",
    "print(\"size of Contracts : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Works_On')\n",
    "print(\"size of Works_On : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Dept_Locations')\n",
    "print(\"size of Dept_Locations : \" + str(list(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(49, )]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = cursor.execute('select count(*) from Project where Pnumber < 50')\n",
    "print(list(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudatorch",
   "language": "python",
   "name": "cudatorch"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "655c12636761ad29ab72f84a68a8a53faa13a1d27df70400707a6bbc70c23f25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

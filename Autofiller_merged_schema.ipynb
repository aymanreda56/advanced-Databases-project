{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST of all, install SSMS (SQL Server MicroSoft)\n",
    "#Second of all, open the SQLQuery1.sql file in SqlServer\n",
    "#Thrid of all, highlight ONLY the first command (create database Brokerage) then click Execute\n",
    "#Fourth of all, highlight the rest of the file lines then click Execute.\n",
    "#by now you should have the database and schema set and done\n",
    "\n",
    "#now you will need to populate it with data\n",
    "\n",
    "#Fifth of all, install pyodbc (nice library btw)\n",
    "\n",
    "#you will then want to connect your database to the ODBC:\n",
    "#   1) open SQL Server\n",
    "#   2) right click on the very first element in object explorer (which is your device obvs)\n",
    "#   3) choose connect\n",
    "#   4) copy the server name\n",
    "#   5) paste it in the server string below\n",
    "\n",
    "\n",
    "#Sixth of all, just run everything below and enjoy :)\n",
    "\n",
    "#OPTIONAL : you don't need to know how to generate the report file, it is so ez though\n",
    "#   just open SSMS\n",
    "#   Select the database \"Brokerage\"\n",
    "#   Right click and select Reports then Standard Reports\n",
    "#   Select any of the reports than seems interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "#to return a random Department Name\n",
    "def GenerateRandName(digits):\n",
    "    Random_dept_name = ''\n",
    "    max_len = random.choice(range(9,40))\n",
    "    while len(Random_dept_name) < max_len:\n",
    "        if(digits):\n",
    "            Random_dept_name = Random_dept_name+(random.choice(alphabet+'123456789'))\n",
    "        else:\n",
    "            Random_dept_name = Random_dept_name+(random.choice(alphabet))\n",
    "    return Random_dept_name\n",
    "\n",
    "def GenerateRandomDate():\n",
    "    randDay = random.choice(range(1,29))\n",
    "    randMonth = random.choice(range(1,12))\n",
    "    randYear = random.choice(range(2000,2023))\n",
    "    return pd.to_datetime(str(randDay) + \"/\"+str(randMonth)+\"/\"+str(randYear), dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Server\n",
      "SQL Server Native Client 11.0\n",
      "SQL Server Native Client RDA 11.0\n",
      "ODBC Driver 17 for SQL Server\n",
      "Microsoft Access Driver (*.mdb, *.accdb)\n",
      "Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)\n",
      "Microsoft Access Text Driver (*.txt, *.csv)\n"
     ]
    }
   ],
   "source": [
    "for driver in pyodbc.drivers():\n",
    "    print(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [00:29<00:00, 6814.23it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Employee.csv')\n",
    "#Columns in the CSV : first_name Minit last_name Address gender BDate Salary\n",
    "#attributes in our database: Fname Minit Lname Bdate Address_ Sex Salary\n",
    "#print(df['first_name'])\n",
    "\n",
    "for i in tqdm(range(200000)):\n",
    "    df.loc[i,'Hours'] = random.choice(range(1,100))\n",
    "    df.loc[i, 'PNO'] = i+1\n",
    "\n",
    "df.to_csv('Employee_merged.csv')\n",
    "\n",
    "#print(df.iloc[:,:].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.execute('delete from Employee')\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0 first_name Minit  last_name  \\\n",
      "0             0           0       Mary     a       Anna   \n",
      "1             1           1       Anna     b       Emma   \n",
      "2             2           2       Emma     c  Elizabeth   \n",
      "3             3           3  Elizabeth     d     Minnie   \n",
      "4             4           4     Minnie     e   Margaret   \n",
      "\n",
      "                                Address       BDate  Sex   Salary  Hours  PNO  \n",
      "0           7353 HIGHLAND RD, STE B 282  2000-01-01  0.0      0.0   12.0  1.0  \n",
      "1               9007 HIGHLAND RD, STE 9  2001-02-02  1.0   3000.0   17.0  2.0  \n",
      "2   5830 S SHERWOOD FOREST BLVD, STE A6  2002-03-03  2.0   6000.0   50.0  3.0  \n",
      "3  4520 S SHERWOOD FOREST BLVD, STE 103  2003-04-04  0.0   9000.0   46.0  4.0  \n",
      "4                 8334 O'HARA CT, STE D  2004-05-05  1.0  12000.0   45.0  5.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting data into Table Employee:   0%|          | 0/300000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "('The SQL contains 7 parameter markers, but 10 parameters were supplied', 'HY000')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m300000\u001b[39m), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minserting data into Table Employee: \u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     23\u001b[0m     lst \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[i,\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m---> 24\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(insert_to_employee, lst)\n\u001b[0;32m     26\u001b[0m connection\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m     28\u001b[0m get_Employees_count \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mselect count (*) from Employee\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: ('The SQL contains 7 parameter markers, but 10 parameters were supplied', 'HY000')"
     ]
    }
   ],
   "source": [
    "#QUERIES TO FILL \"Employee\"\n",
    "\n",
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute('delete from Employee')\n",
    "connection.commit()\n",
    "\n",
    "df = pd.read_csv('Employee_merged.csv')\n",
    "print(df.head())\n",
    "\n",
    "insert_to_employee = 'INSERT INTO Employee (Fname, Minit, Lname, Address_, Bdate, Sex, Salary) VALUES (?,?,?, ?, ?, ?, ?)'\n",
    "select_all_from_employee = \"select * from Employee\"\n",
    "\n",
    "for i in tqdm(range(300000), desc=\"inserting data into Table Employee: \"):\n",
    "    lst = df.iloc[i,1:].values.tolist()\n",
    "    cursor.execute(insert_to_employee, lst)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "get_Employees_count = \"select count (*) from Employee\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "count = cursor.execute(get_Employees_count)\n",
    "print(list(count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making Department.csv: 100%|██████████| 10000/10000 [00:16<00:00, 592.04it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Department Attributes\n",
    "Dname nvarchar(50),\n",
    "Dnumber int identity (1,1) Primary Key NOT NULL,\n",
    "Mgr_SSN int foreign key references Employee(SSN),\n",
    "Mgr_Start_Date DATE\n",
    "'''\n",
    "Dept_df = pd.DataFrame()\n",
    "Dept_df['Dname'] = GenerateRandName(True)\n",
    "Dept_df['Mgr_SSN'] = random.choice(range(1,30))\n",
    "Dept_df['Mgr_Start_Date'] = pd.to_datetime('11/11/2000', dayfirst=True)\n",
    "\n",
    "for i in tqdm(range(0,10000), desc=\"making Department.csv: \"):\n",
    "    Dept_df.loc[i, 'Dname'] = GenerateRandName(True)\n",
    "    Dept_df.loc[i, 'Mgr_SSN'] = i+13000\n",
    "    Dept_df.loc[i, 'Mgr_Start_Date'] = GenerateRandomDate()\n",
    "    \n",
    "\n",
    "\n",
    "while(len(Dept_df) < 120000):\n",
    "    Dept_df = pd.concat((Dept_df, Dept_df),axis=0)\n",
    "Dept_df.to_csv('Department_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "connection.commit()\n",
    "cursor.execute('delete from Department')\n",
    "connection.commit()\n",
    "\n",
    "data = cursor.execute('select * from Employee where SSN = 30')\n",
    "print(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                  Dname  Mgr_SSN Mgr_Start_Date\n",
      "0           0                    MSeVPJz2FZkbEsl734A  13000.0     2021-01-18\n",
      "1           1                5LouE34pcKd44XYMkMI2Vb9  13001.0     2014-06-09\n",
      "2           2    mc8Yi7sxeoPPHehuu21lsEHbOQlvfDfho33  13002.0     2020-09-04\n",
      "3           3  PR88RApstnHy6bUqxQrDqgAUkvNQL3maeZfZX  13003.0     2018-07-13\n",
      "4           4              ksB7bH5MMkw2sJwGYFfinLlJi  13004.0     2001-11-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting data into Department: 100%|██████████| 100000/100000 [00:42<00:00, 2359.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100000, )]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute('delete from Department')\n",
    "connection.commit()\n",
    "\n",
    "Dept_df = pd.read_csv('Department_100k.csv')\n",
    "print(Dept_df.head())\n",
    "\n",
    "insert_to_Department= \"INSERT INTO Department (Dname, Mgr_SSN, Mgr_Start_Date) VALUES(?,?, ?)\"\n",
    "select_all_from_Department = \"select * from Department\"\n",
    "get_Department_count = \"select count (*) from Department\"\n",
    "\n",
    "for i in tqdm(range (100000), desc=\"inserting data into Department: \"):\n",
    "    lst = Dept_df.iloc[i,1:].values.tolist()\n",
    "    cursor.execute(insert_to_Department, lst)\n",
    "    \n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Department_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making Dept_Locations.csv: 100%|██████████| 900000/900000 [17:09<00:00, 873.97it/s]  \n"
     ]
    }
   ],
   "source": [
    "''' DEPT LOCATION\n",
    "\n",
    "create table Dept_Locations\n",
    "(\n",
    "Dnumber INT foreign key references Department(Dnumber),\n",
    "Dlocation nvarchar(50) NOT NULL,\n",
    "CONSTRAINT Department_KEY_COMPOSITE PRIMARY KEY (Dnumber, Dlocation)\n",
    ");\n",
    "'''\n",
    "\n",
    "DeptLoc_df = pd.DataFrame()\n",
    "Address_df = pd.read_csv('Address.csv')\n",
    "\n",
    "temp_df = DeptLoc_df\n",
    "for i in tqdm(range(900000), desc=\"Making Dept_Locations.csv: \"):\n",
    "    temp_df.loc[i,'Dnumber'] = i+1\n",
    "    temp_df.loc[i,'Dlocation'] = Address_df.loc[random.choice(range(1,400000)), 'FULL ADDRESS']\n",
    "    if(i%20000 == 0):\n",
    "        DeptLoc_df = pd.concat((DeptLoc_df, temp_df), axis=0)\n",
    "        temp_df = pd.DataFrame()\n",
    "        DeptLoc_df.to_csv('Dept_Locations.csv')\n",
    "\n",
    "\n",
    "\n",
    "DeptLoc_df = pd.concat((DeptLoc_df, temp_df), axis=0)\n",
    "DeptLoc_df.to_csv('Dept_Locations_100ن.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.execute('Delete from Dept_Locations')\n",
    "connection.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Dnumber                  Dlocation\n",
      "0           1      1.0          10082 E POMONA DR\n",
      "1           2      2.0          16933 TENEIYA AVE\n",
      "2           3      3.0          13630 LANDMARK DR\n",
      "3           4      4.0          11733 SUN BELT CT\n",
      "4           5      5.0  17100-17400 BLACKWATER RD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting into Dept_Locations: 100%|██████████| 100/100 [00:13<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100000, )]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "DeptLoc_df = pd.read_csv('Dept_Locations.csv')\n",
    "print(DeptLoc_df.head())\n",
    "\n",
    "insert_to_DeptLocation = \"INSERT INTO Dept_Locations (Dlocation) VALUES(?)\"\n",
    "select_all_from_DeptLocations = \"select * from Dept_Locations\"\n",
    "get_Dept_location_count = \"select count (*) from Dept_Locations\"\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(100),desc=\"inserting into Dept_Locations: \"):\n",
    "    lst = DeptLoc_df.iloc[i*1000:(i+1)*1000,2].values.tolist()\n",
    "    for s in lst:\n",
    "        try:\n",
    "            cursor.execute(insert_to_DeptLocation, s)\n",
    "        except:\n",
    "            pass\n",
    "   \n",
    "\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Dept_location_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making Intern.csv: 100%|██████████| 150000/150000 [44:55<00:00, 55.65it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "''' Intern TABLE ATTRIBUTES\n",
    "(\n",
    "SSN int identity (3000000,1) primary key Not NULL,\n",
    "Fname nvarchar(50),\n",
    "Minit varchar,\n",
    "Lname nvarchar(50),\n",
    "Bdate DATE,\n",
    "Address_ nvarchar(50),\n",
    "Sex tinyint check(Sex between 0 and 2),\n",
    "Salary int,\n",
    "Major nvarchar(50),\n",
    "PNO INT foreign key references Project(Pnumber),\n",
    "Super_SSN int foreign key references Employee(SSN)\n",
    ");\n",
    "'''\n",
    "\n",
    "names_df = pd.read_csv('Names.csv')\n",
    "Address_df = pd.read_csv('Address.csv')\n",
    "jobs_df = pd.read_csv('Jobs.csv')\n",
    "\n",
    "#new empty dataframe\n",
    "df_intern = pd.DataFrame()\n",
    "#df_intern['SSN']=         auto incremented\n",
    "df_intern['Fname']= ['Ayman', 'Mohamed']\n",
    "df_intern['Minit']= ['M', 'R']\n",
    "df_intern['Lname']= ['Reda', 'Abdo']\n",
    "df_intern['Bdate']= [pd.to_datetime(\"20/12/2004\", dayfirst=True), pd.to_datetime(\"11/11/2000\", dayfirst=True)]\n",
    "df_intern['Address_']= [Address_df.loc[1, 'FULL ADDRESS'], Address_df.loc[3, 'FULL ADDRESS']]\n",
    "df_intern['Sex']= [1,1]\n",
    "df_intern['Salary']= [2000,3000]\n",
    "df_intern['Major']= [\"Computer\", \"Engineering\"]\n",
    "df_intern['Super_SSN']= [1, 2]\n",
    "\n",
    "\n",
    "temp_df = df_intern\n",
    "for i in tqdm(range(150000),desc=\"making Intern.csv: \"):\n",
    "    temp_df.loc[i, 'Fname'] = names_df.loc[i%1000000, 'Name']\n",
    "    temp_df.loc[i, 'Minit'] = random.choice(alphabet)\n",
    "    temp_df.loc[i, 'Lname'] = names_df.loc[i%1000000, 'Name']\n",
    "    temp_df.loc[i, 'Address_'] = Address_df.loc[i%1000000, 'FULL ADDRESS']\n",
    "    \n",
    "    randSex = random.choice(range(0,3))\n",
    "    randSalary = random.choice(range(1, 100000))\n",
    "    \n",
    "    temp_df.loc[i, 'Bdate'] = GenerateRandomDate()\n",
    "    temp_df.loc[i, 'Sex'] = randSex\n",
    "    temp_df.loc[i, 'Salary'] = randSalary\n",
    "    temp_df.loc[i, 'Major'] = jobs_df.loc[i%5000, 'top related titles 19']\n",
    "    temp_df.loc[i, 'Super_SSN'] = random.choice(range(1,10000))                                  #the first 500000 employees are intern supervisors\n",
    "    \n",
    "\n",
    "df_intern = pd.concat((df_intern, temp_df), axis=0)\n",
    "df_intern.to_csv('Intern_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      Fname Minit      Lname       Bdate  \\\n",
      "0           0       Mary     m       Mary  2021-02-22   \n",
      "1           1       Anna     g       Anna  2022-03-28   \n",
      "2           2       Emma     P       Emma  2018-10-13   \n",
      "3           3  Elizabeth     U  Elizabeth  2003-08-19   \n",
      "4           4     Minnie     w     Minnie  2017-04-27   \n",
      "\n",
      "                               Address_  Sex   Salary                  Major  \\\n",
      "0           7353 HIGHLAND RD, STE B 282  1.0  59279.0        general manager   \n",
      "1               9007 HIGHLAND RD, STE 9  1.0  83613.0          sales manager   \n",
      "2   5830 S SHERWOOD FOREST BLVD, STE A6  1.0  88228.0              principal   \n",
      "3  4520 S SHERWOOD FOREST BLVD, STE 103  0.0  12071.0                  owner   \n",
      "4                 8334 O'HARA CT, STE D  0.0  84155.0   chief executive offi   \n",
      "\n",
      "   Super_SSN  \n",
      "0     7748.0  \n",
      "1     7845.0  \n",
      "2     8883.0  \n",
      "3     6157.0  \n",
      "4     1797.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting into Intern: 100%|██████████| 100000/100000 [02:04<00:00, 802.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(300000, )]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "df_intern = pd.read_csv('Intern_100k.csv')\n",
    "print(df_intern.head())\n",
    "\n",
    "insert_to_Intern = \"INSERT INTO Intern (Fname, Minit, Lname, Bdate, Address_, Sex, Salary, Major, Super_SSN) VALUES(?,?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "select_all_from_Intern = \"select * from Intern\"\n",
    "get_Intern_count = \"select count (*) from Intern\"\n",
    "get_Employees_count = \"select count (*) from Employee\"\n",
    "\n",
    "for i in tqdm(range(100000),desc=\"inserting into Intern: \"):\n",
    "    lst = df_intern.iloc[i,1:].values.tolist()\n",
    "    try:\n",
    "        cursor.execute(insert_to_Intern, lst)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Employees_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           Pname  \\\n",
      "0           0                              advanced databases   \n",
      "1           1                                              9F   \n",
      "2           2                           LEZ3SwJIykqigwhJ1bPw7   \n",
      "3           3             Vyp3AQZxOF4zQNki7hAU5m5B7X4gY1o3cy6   \n",
      "4           4  ffI4FhNEyXiK9ri5QToVRIBkxg5pUCgOV1m7BB868r2nm8   \n",
      "\n",
      "                              Plocation  DNO  \n",
      "0           7353 HIGHLAND RD, STE B 282  1.0  \n",
      "1               9007 HIGHLAND RD, STE 9  2.0  \n",
      "2   5830 S SHERWOOD FOREST BLVD, STE A6  3.0  \n",
      "3  4520 S SHERWOOD FOREST BLVD, STE 103  4.0  \n",
      "4                 8334 O'HARA CT, STE D  5.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting data into Table Project: 100%|██████████| 100/100 [01:15<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100000, )]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "project_df = pd.read_csv('Project.csv')\n",
    "print(project_df.head())\n",
    "\n",
    "insert_to_Project = 'INSERT INTO Project (Pname, Plocation, DNO) VALUES (?,?, ?)'\n",
    "select_all_from_Project = \"select * from Project\"\n",
    "\n",
    "for i in tqdm(range(100), desc=\"inserting data into Table Project: \"):\n",
    "    lst = project_df.iloc[(i)*1000: (i+1)*1000,1:].values.tolist()\n",
    "    cursor.executemany(insert_to_Project, lst)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "get_Project_count = \"select count (*) from Project\"\n",
    "\n",
    "cursor = connection.cursor()\n",
    "count = cursor.execute(get_Project_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "create table Works_On\n",
    "(\n",
    "ESSN INT foreign key references Employee(SSN),\n",
    "PNO INT foreign key references Project(Pnumber),\n",
    "Hours INT,\n",
    "CONSTRAINT WorksOn_KEY_COMPOSITE PRIMARY KEY (ESSN, PNO)\n",
    ");\n",
    "\n",
    "'''\n",
    "\n",
    "#new empty dataframe\n",
    "df_workson = pd.Dataframe()\n",
    "\n",
    "df_workson[0,'ESSN']= 1\n",
    "df_workson[0,'PNO']= 1\n",
    "df_workson[0,'Hours']= 19\n",
    "\n",
    "PNO_counter = 1\n",
    "tempdf = df_workson\n",
    "for i in tqdm(range(2900000), desc=\"making Works_On.csv: \"):\n",
    "    tempdf.loc[i, 'ESSN'] = i+1\n",
    "    tempdf.loc[i, 'PNO'] = PNO_counter\n",
    "    temp_df.loc[i, 'Hours'] = random.randint(15, 50)\n",
    "    if(i%17000 == 0):\n",
    "        PNO_counter = PNO_counter + 1\n",
    "        df_workson = pd.concat((df_workson, temp_df),axis=0)\n",
    "        temp_df = pd.DataFrame()\n",
    "        df_workson.to_csv('Works_On.csv')\n",
    "\n",
    "df_workson = pd.concat((df_workson, temp_df),axis=0)\n",
    "df_workson.to_csv('Works_On_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  ESSN  PNO  Hours\n",
      "0           1   1.0  1.0   46.0\n",
      "1           2   2.0  2.0   44.0\n",
      "2           3   3.0  2.0   45.0\n",
      "3           4   4.0  2.0   24.0\n",
      "4           5   5.0  2.0   20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting into Works_On: 100%|██████████| 100/100 [00:09<00:00, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100000, )]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "df_workson = pd.read_csv('Works_On.csv')\n",
    "print(df_workson.head())\n",
    "\n",
    "insert_to_Works_On = \"INSERT INTO Works_On (ESSN, PNO, Hours) VALUES(?,?,?)\"\n",
    "select_all_from_Works_On = \"select * from Works_On\"\n",
    "get_Works_On_count = \"select count (*) from Works_On\"\n",
    "\n",
    "\n",
    "for i in tqdm(range(100), desc=\"inserting into Works_On: \"):\n",
    "    lst = df_workson.iloc[i*1000:(i+1)*1000,1:].values.tolist()\n",
    "    cursor.executemany(insert_to_Works_On, lst)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Works_On_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "create table Dependent_\n",
    "(\n",
    "ESSN INT foreign key references Employee(SSN),\n",
    "Dependent_Name nvarchar(50) NOT NULL,\n",
    "Sex tinyint check(Sex between 0 and 2),\n",
    "Bdate DATE,\n",
    "Relationship nvarchar(50),\n",
    "CONSTRAINT Dependent_KEY_COMPOSITE PRIMARY KEY (ESSN, Dependent_Name)\n",
    ");\n",
    "'''\n",
    "\n",
    "\n",
    "Relationship_df = pd.read_csv('Relationship.csv')\n",
    "\n",
    "#new empty dataframe\n",
    "df_Dependent = pd.DataFrame()\n",
    "\n",
    "df_Dependent[0,'ESSN']= 1\n",
    "df_Dependent[0,'Dependent_Name']= \"Akram\"\n",
    "df_Dependent[0,'Sex']= 1\n",
    "df_Dependent[0,'Bdate']= pd.to_datetime('11/11/2000', dayfirst=True)\n",
    "df_Dependent[0,'Relationship']= \"Father\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "temp_df = df_Dependent\n",
    "for i in tqdm(range(2900000), desc=\"making Dependent.csv : \"):\n",
    "    temp_df.loc[i, 'ESSN'] = i+1\n",
    "    temp_df.loc[i, 'Dependent_Name'] = GenerateRandName(False)\n",
    "    temp_df.loc[i, 'Sex'] = random.randint(0, 2)\n",
    "    temp_df.loc[i, 'Bdate'] = GenerateRandomDate()\n",
    "    temp_df.loc[i, 'Relationship'] = Relationship_df.loc[random.randint(0,970),'Relationship']\n",
    "    if(i%17000 == 0):\n",
    "        df_Dependent = pd.concat((df_Dependent, temp_df), axis=0)\n",
    "        temp_df = pd.DataFrame()\n",
    "        df_Dependent.to_csv('Dependent.csv')\n",
    "\n",
    "\n",
    "df_Dependent = pd.concat((df_Dependent, temp_df), axis=0)\n",
    "df_Dependent.to_csv('Dependent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.execute(\"delete from Dependent_\")\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Dependent = pd.read_csv('Dependent.csv')\n",
    "df_Dependent.head()\n",
    "df_Dependent = df_Dependent.iloc[:, 2:]\n",
    "df_Dependent.to_csv('Dependent.csv')\n",
    "df_Dependent = pd.read_csv('Dependent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  ESSN                      Dependent_Name  Sex  \\\n",
      "0             0           0   1.0        paZKVTQLByxdXhOCpyxXxLUpiqqj  1.0   \n",
      "1             1           1   2.0       FMQDdqvlxinFUqMVSuGIbqbkLorMc  1.0   \n",
      "2             2           2   3.0            CjuVAbakpmWAYMFsHoCqobKc  2.0   \n",
      "3             3           3   4.0  MmGysbOQtdhSRszpXLMzszspphVNUHeuzT  0.0   \n",
      "4             4           4   5.0                VVXLuargiWnLGulRAkVD  2.0   \n",
      "\n",
      "        Bdate Relationship  \n",
      "0  2019-09-06       Lotlux  \n",
      "1  2001-07-06  Mat Lam Tam  \n",
      "2  2005-08-17     Wrapsafe  \n",
      "3  2001-06-24     Treeflex  \n",
      "4  2017-09-12       Vagram  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting into Dependent_ : 100%|██████████| 100/100 [00:15<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100000, )]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "df_Dependent= pd.read_csv('Dependent.csv')\n",
    "print(df_Dependent.head())\n",
    "\n",
    "insert_to_Dependent_ = \"INSERT INTO Dependent_ (ESSN, Dependent_Name, Sex, Bdate, Relationship) VALUES(?,?,?,?,?)\"\n",
    "select_all_from_Dependent_ = \"select * from Dependent_\"\n",
    "get_Dependent__count = \"select count (*) from Dependent_\"\n",
    "\n",
    "\n",
    "for i in tqdm(range(100), desc=\"inserting into Dependent_ : \"):\n",
    "    lst = df_Dependent.iloc[i*1000:(i+1)*1000,2:].values.tolist()\n",
    "    cursor.executemany(insert_to_Dependent_, lst)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Dependent__count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  (0, 'Name_Company') Date_created  ProjectID  Product  \\\n",
      "0           0                  NaN   2013-05-21        2.0    63999   \n",
      "1           1                  NaN   2011-10-03        3.0    37891   \n",
      "2           2                  NaN   2010-02-24        4.0    88587   \n",
      "3           3                  NaN   2015-08-24        5.0   121650   \n",
      "4           4                  NaN   2019-02-16        6.0   162283   \n",
      "\n",
      "       Price Date_of_Contract   Emp_Name  Emp_SSN Contractor_Name   Cont_SSN  \\\n",
      "0  1063907.0       2000-10-21       Anna      1.0            Mary  4000001.0   \n",
      "1  1381986.0       2000-10-21       Emma      2.0            Anna  4000002.0   \n",
      "2   339553.0       2000-10-21  Elizabeth      3.0            Emma  4000003.0   \n",
      "3  1849411.0       2000-10-21     Minnie      4.0       Elizabeth  4000004.0   \n",
      "4   755588.0       2000-10-21   Margaret      5.0          Minnie  4000005.0   \n",
      "\n",
      "                      Delivery_Location                           Name_Company  \n",
      "0               9007 HIGHLAND RD, STE 9  ciqDzQscRAzPZFxAuJQRVCirDrVjOpBWrLxnZ  \n",
      "1   5830 S SHERWOOD FOREST BLVD, STE A6                     KFqJgCHGVaErlKgdpZ  \n",
      "2  4520 S SHERWOOD FOREST BLVD, STE 103        ukVppMOmkNpJZkERpIqIREwGBNmPzJB  \n",
      "3                 8334 O'HARA CT, STE D                   wXRnxJuvZEnAOFJKmUaU  \n",
      "4               4250 BLOUNT RD, UNIT 14  ajOumJOykLPVbzPznvsvBRLhBseNWNWcsaixK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inserting data into table Contracts: 100%|██████████| 90/90 [05:07<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(90000, )]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "Contract_df = pd.read_csv('Contracts.csv')\n",
    "print(Contract_df.head())\n",
    "\n",
    "insert_to_Contracts= \"INSERT INTO Contracts (Date_created, ProjectID, Product, Price, Date_of_Contract, Emp_Name, Emp_SSN, Contractor_Name, Cont_SSN, Delivery_Location,Name_Company) VALUES(?,?,?, ?,?,?,?,?,?,?,?)\"\n",
    "select_all_from_Contracts = \"select * from Contracts\"\n",
    "get_Contracts_count = \"select count (*) from Contracts\"\n",
    "\n",
    "\n",
    "for i in tqdm(range(90), desc=\"inserting data into table Contracts\"):\n",
    "    lst = Contract_df.iloc[i*1000:(i+1)*1000,2:].values.tolist()\n",
    "    cursor.executemany(insert_to_Contracts, lst)\n",
    "\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "count = cursor.execute(get_Contracts_count)\n",
    "print(list(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of Employee : [(300000, )]\n",
      "size of Department : [(100000, )]\n",
      "size of Project : [(100000, )]\n",
      "size of Intern : [(2026, )]\n",
      "size of Contracts : [(90000, )]\n",
      "size of Works_On : [(100000, )]\n",
      "size of Dept_Locations : [(100000, )]\n"
     ]
    }
   ],
   "source": [
    "server = 'LAPTOP-66BOPJMV\\SQLEXPRESS'\n",
    "database = 'Brokerage_Firm_new_schema'\n",
    "\n",
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};\\\n",
    "                            server='+server+';\\\n",
    "                            database='+database+';\\\n",
    "                            trusted_connection=yes;')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "\n",
    "data = cursor.execute('select count(*) from Employee')\n",
    "print(\"size of Employee : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Department')\n",
    "print(\"size of Department : \" + str(list(data)))\n",
    "\n",
    "\n",
    "data = cursor.execute('select count(*) from Project')\n",
    "print(\"size of Project : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Intern')\n",
    "print(\"size of Intern : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Contracts')\n",
    "print(\"size of Contracts : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Works_On')\n",
    "print(\"size of Works_On : \" + str(list(data)))\n",
    "\n",
    "data = cursor.execute('select count(*) from Dept_Locations')\n",
    "print(\"size of Dept_Locations : \" + str(list(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudatorch",
   "language": "python",
   "name": "cudatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "655c12636761ad29ab72f84a68a8a53faa13a1d27df70400707a6bbc70c23f25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
